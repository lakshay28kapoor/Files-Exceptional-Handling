{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzjvgMqV5KRa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n",
        "Ans.In Python, the choice between **multithreading** and **multiprocessing** depends heavily on the nature of the tasks, especially because of Python's **Global Interpreter Lock (GIL)**, which influences how threading works. Let's explore scenarios where each is preferable in Python, considering the GIL's effect.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Multithreading in Python:**\n",
        "\n",
        "Multithreading in Python refers to the concurrent execution of tasks using multiple threads in a single process. Python’s Global Interpreter Lock (GIL) allows only one thread to execute Python bytecode at a time, which limits the efficiency of threading for CPU-bound tasks. However, **multithreading** can still be useful in specific scenarios, particularly those involving I/O-bound tasks.\n",
        "\n",
        "#### **When Multithreading is Preferable in Python:**\n",
        "- **I/O-bound tasks:** Since the GIL only affects CPU-bound operations, multithreading still excels in I/O-bound operations where threads spend a significant amount of time waiting for external operations (disk, network, etc.). During I/O waits, the GIL is released, allowing other threads to continue processing.\n",
        "  - **Example:** Downloading multiple files, web scraping, or interacting with databases. Each thread waits for network responses or file I/O, making multithreading efficient despite the GIL.\n",
        "\n",
        "    ```python\n",
        "    import threading\n",
        "    import requests\n",
        "\n",
        "    def download_file(url):\n",
        "        response = requests.get(url)\n",
        "        with open(url.split('/')[-1], 'wb') as file:\n",
        "            file.write(response.content)\n",
        "\n",
        "    urls = ['https://example.com/file1.zip', 'https://example.com/file2.zip']\n",
        "    threads = [threading.Thread(target=download_file, args=(url,)) for url in urls]\n",
        "\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "    ```\n",
        "\n",
        "- **Tasks requiring shared memory:** Threads in Python share the same memory space, so tasks that require shared memory can benefit from threading.\n",
        "  - **Example:** If you are working on a GUI application where you want the main thread to handle user interaction and background threads to handle secondary tasks (e.g., file saving, processing), threading is useful.\n",
        "\n",
        "- **Low overhead:** Threads are lightweight compared to processes and incur less memory overhead. They are created quickly and have faster context switches.\n",
        "  - **Example:** Running periodic background tasks like timers, logging, or monitoring.\n",
        "\n",
        "#### **When Multithreading in Python is Not Suitable:**\n",
        "- **CPU-bound tasks:** Due to the GIL, Python threads cannot execute CPU-bound code in parallel. If the task requires significant CPU resources (e.g., heavy mathematical computations), the GIL will serialize thread execution, making threading inefficient.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Multiprocessing in Python:**\n",
        "\n",
        "Multiprocessing in Python involves creating multiple processes, each with its own memory space. Each process runs independently, and since each process has its own Python interpreter, the GIL does not restrict multiprocessing. This makes **multiprocessing** ideal for CPU-bound tasks that require parallel execution.\n",
        "\n",
        "#### **When Multiprocessing is Preferable in Python:**\n",
        "- **CPU-bound tasks:** For tasks that require substantial CPU resources, multiprocessing allows for true parallelism by utilizing multiple CPU cores. Since each process has its own Python interpreter, the GIL is bypassed, and each process can run on a different core.\n",
        "  - **Example:** Performing complex calculations (e.g., prime number generation, simulations, or machine learning model training).\n",
        "\n",
        "    ```python\n",
        "    import multiprocessing\n",
        "    import math\n",
        "\n",
        "    def is_prime(n):\n",
        "        if n < 2:\n",
        "            return False\n",
        "        for i in range(2, int(math.sqrt(n)) + 1):\n",
        "            if n % i == 0:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    if __name__ == '__main__':\n",
        "        numbers = [i for i in range(10_000, 20_000)]\n",
        "        with multiprocessing.Pool() as pool:\n",
        "            results = pool.map(is_prime, numbers)\n",
        "        print(results)\n",
        "    ```\n",
        "\n",
        "- **True parallelism:** Multiprocessing allows true parallel execution of processes on different CPU cores, ideal for maximizing CPU utilization.\n",
        "  - **Example:** Parallel processing of independent tasks, like image or video processing, where each process handles a different part of the workload.\n",
        "\n",
        "- **Process isolation:** Since each process runs in its own memory space, multiprocessing is useful when tasks need to be isolated. Crashing or memory leaks in one process won't affect the others.\n",
        "  - **Example:** A web server where each request is handled in a separate process ensures that if one process fails, it doesn’t take down the whole server.\n",
        "\n",
        "- **Memory-bound tasks:** When each process handles large, independent datasets, multiprocessing is beneficial since each process can manage its memory separately.\n",
        "  - **Example:** Large data processing tasks where each process works on a separate portion of a dataset.\n",
        "\n",
        "#### **When Multiprocessing in Python is Not Suitable:**\n",
        "- **High inter-process communication (IPC) needs:** If tasks need to frequently communicate or share data, multiprocessing can be inefficient. Transferring data between processes involves more overhead (via queues, pipes, or shared memory), making it slower than threading.\n",
        "  - **Example:** Tasks where large amounts of data are constantly exchanged between processes can lead to performance bottlenecks.\n",
        "\n",
        "- **Higher resource overhead:** Creating and managing processes is more resource-intensive than threads. Each process consumes its own memory space, so if the number of processes grows too large, it can lead to high memory usage.\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary of When to Use Multithreading vs. Multiprocessing in Python:**\n",
        "\n",
        "#### **Multithreading in Python is Better For:**\n",
        "- **I/O-bound tasks** (waiting for network responses, file I/O).\n",
        "- **Tasks requiring shared memory** (such as UI management in GUI applications).\n",
        "- **Low CPU utilization tasks** (e.g., background logging, monitoring).\n",
        "- **Low overhead operations** (fast, lightweight tasks that don't need heavy computation).\n",
        "\n",
        "#### **Multiprocessing in Python is Better For:**\n",
        "- **CPU-bound tasks** (e.g., heavy number crunching, data processing).\n",
        "- **Tasks requiring parallelism** across multiple CPU cores.\n",
        "- **Memory-bound tasks** that need isolated memory spaces.\n",
        "- **Independent tasks** where inter-process communication is minimal.\n",
        "\n",
        "---\n",
        "\n",
        "Both multithreading and multiprocessing have their place in Python, and the choice between them depends on the nature of your workload (I/O-bound vs. CPU-bound), memory needs, and whether true parallelism is required.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mrqY5rkR5K8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
        "Ans.### **Process Pool in Python:**\n",
        "\n",
        "A **process pool** is a programming abstraction that manages a collection (or pool) of worker processes for parallel execution. In Python, this is typically handled using the `multiprocessing.Pool` class, which simplifies the management of multiple processes and helps distribute tasks efficiently among them.\n",
        "\n",
        "Instead of creating and managing individual processes manually, the process pool allows you to specify the number of worker processes that will be used to perform tasks. The pool assigns tasks to available processes, manages their execution, and gathers the results.\n",
        "\n",
        "---\n",
        "\n",
        "### **How Process Pool Helps Manage Multiple Processes Efficiently:**\n",
        "\n",
        "1. **Task Distribution and Load Balancing:**\n",
        "   - The pool manages the distribution of tasks across worker processes. You can submit tasks to the pool, and it will allocate them to idle processes. This ensures that all CPU cores are utilized efficiently and evenly.\n",
        "   - By controlling the number of processes, the pool prevents overloading the system with too many processes, which could otherwise lead to high resource usage.\n",
        "\n",
        "2. **Simplifies Process Creation and Management:**\n",
        "   - Instead of manually creating and managing individual processes, you can submit tasks to the pool using high-level functions such as `map()`, `apply()`, `apply_async()`, or `starmap()`. The pool automatically handles process creation, task execution, and resource cleanup, which simplifies the code.\n",
        "   - The pool also manages process termination after the tasks are completed, avoiding memory leaks or zombie processes.\n",
        "\n",
        "3. **Concurrency Without Complex Synchronization:**\n",
        "   - The pool provides a convenient way to run tasks concurrently without having to deal with complex inter-process communication (IPC) or synchronization mechanisms. It abstracts away many low-level details such as starting processes and managing shared resources.\n",
        "   - Functions like `apply_async()` allow tasks to run asynchronously, enabling you to launch many tasks without waiting for them to complete before launching new ones.\n",
        "\n",
        "4. **Efficient Resource Utilization:**\n",
        "   - The process pool limits the number of processes that run concurrently, usually based on the number of CPU cores available (`os.cpu_count()`), which helps in optimizing resource usage and avoiding over-committing system resources.\n",
        "   - By reusing a fixed number of worker processes instead of constantly creating and destroying them, process pools reduce the overhead associated with process creation and destruction, which can be time-consuming and resource-heavy.\n",
        "\n",
        "---\n",
        "\n",
        "### **Using a Process Pool in Python:**\n",
        "\n",
        "Here’s a basic example that demonstrates how to use the `multiprocessing.Pool` to parallelize a CPU-bound task, like calculating squares of numbers.\n",
        "\n",
        "```python\n",
        "import multiprocessing\n",
        "\n",
        "# Function to perform some CPU-bound task\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # List of numbers\n",
        "    numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "    \n",
        "    # Create a pool with 4 worker processes\n",
        "    with multiprocessing.Pool(processes=4) as pool:\n",
        "        # Use pool.map to apply the square function to each number in parallel\n",
        "        results = pool.map(square, numbers)\n",
        "    \n",
        "    print(results)\n",
        "```\n",
        "\n",
        "#### **Explanation:**\n",
        "- A process pool with 4 workers is created (`Pool(processes=4)`).\n",
        "- The `pool.map()` function applies the `square()` function to each number in the `numbers` list, distributing the tasks among the available worker processes.\n",
        "- The pool ensures that no more than 4 processes run concurrently, and it waits for all processes to finish before gathering the results.\n",
        "- Once the task is complete, the pool terminates all the worker processes and returns the results.\n",
        "\n",
        "---\n",
        "\n",
        "### **Common Pool Functions in Python:**\n",
        "\n",
        "- **`Pool.map(function, iterable)`**:\n",
        "  - Applies the function to each element of the iterable, distributing the tasks across the worker processes, and returns the result. It's similar to Python’s built-in `map()` function but runs in parallel.\n",
        "\n",
        "- **`Pool.apply(function, args)`**:\n",
        "  - Executes a single function with the given arguments in one of the pool’s worker processes and returns the result. This is synchronous and blocks until the task is complete.\n",
        "\n",
        "- **`Pool.apply_async(function, args)`**:\n",
        "  - Like `apply()`, but it runs asynchronously. You can launch a function to run in the background without waiting for the result immediately.\n",
        "\n",
        "- **`Pool.starmap(function, iterable_of_tuples)`**:\n",
        "  - Similar to `map()`, but instead of passing a single argument to the function, it passes multiple arguments from each tuple in the iterable to the function.\n",
        "\n",
        "- **`Pool.close()`**:\n",
        "  - Prevents any more tasks from being submitted to the pool. The worker processes will exit once all tasks currently in the queue are completed.\n",
        "\n",
        "- **`Pool.join()`**:\n",
        "  - Waits for all worker processes to complete before moving forward. It should be called after `close()` to ensure all processes finish execution.\n",
        "\n",
        "---\n",
        "\n",
        "### **Benefits of Using Process Pool:**\n",
        "- **Efficient parallelism:** You can parallelize tasks across multiple processes without worrying about managing the lifecycle of each process manually.\n",
        "- **Optimal CPU usage:** You can control the number of processes, which allows you to take full advantage of all available CPU cores without overloading the system.\n",
        "- **Abstraction of complexity:** The process pool simplifies concurrency by handling task distribution, process management, and result aggregation automatically.\n",
        "- **Asynchronous capabilities:** You can perform tasks asynchronously using `apply_async()` or `map_async()`, allowing you to execute long-running operations in the background while continuing other work.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion:**\n",
        "\n",
        "In Python, a **process pool** is an efficient way to manage multiple processes and perform parallel tasks. It abstracts away the complexity of process management, distributes work evenly across worker processes, and optimizes the usage of system resources. It is particularly beneficial for CPU-bound tasks where parallelism can improve performance."
      ],
      "metadata": {
        "id": "ftIxjbLA6dbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Explain what multiprocessing is and why it is used in Python programs\n",
        "Ans.### **What is Multiprocessing?**\n",
        "\n",
        "**Multiprocessing** is a programming technique that involves the use of multiple **processes** to execute tasks concurrently. In contrast to multithreading, where multiple threads share the same memory space, each process in multiprocessing has its own separate memory space. Multiprocessing allows tasks to be executed in **parallel** on different CPU cores, thus fully utilizing the hardware resources of modern multicore processors.\n",
        "\n",
        "In Python, the `multiprocessing` module enables you to create multiple processes that can run in parallel. Each process has its own Python interpreter and memory space, which allows Python programs to bypass the limitations of the **Global Interpreter Lock (GIL)**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why Multiprocessing is Used in Python Programs**\n",
        "\n",
        "Multiprocessing is used in Python programs primarily to overcome the limitations of the **Global Interpreter Lock (GIL)** and to take full advantage of modern multi-core processors. Here are some key reasons why multiprocessing is beneficial in Python:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Overcoming the Global Interpreter Lock (GIL):**\n",
        "\n",
        "- **The GIL in Python:** The GIL is a mutex that allows only one thread to execute Python bytecode at a time. This is a significant limitation in **CPU-bound** tasks, as it prevents multiple threads from executing in parallel on multiple CPU cores.\n",
        "- **How Multiprocessing Bypasses the GIL:** Since each process in multiprocessing runs its own Python interpreter, each process is not constrained by the GIL. This allows processes to run truly in parallel, utilizing multiple CPU cores.\n",
        "\n",
        "  **When this matters:** For CPU-bound tasks such as complex computations, data processing, or tasks that require a lot of CPU cycles, multiprocessing can achieve real parallelism, which is impossible with multithreading due to the GIL.\n",
        "\n",
        "  **Example:** Performing numerical computations, such as calculating large prime numbers or executing machine learning models, can be sped up by distributing the workload across multiple CPU cores.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. True Parallelism:**\n",
        "\n",
        "- **Multicore Utilization:** Multiprocessing allows programs to leverage **multiple CPU cores** efficiently. Each process runs independently on a separate CPU core, enabling true parallel execution. This results in faster completion of tasks, especially for **CPU-bound tasks** that require heavy computation.\n",
        "  \n",
        "  **Example:** In an image-processing task, each core can handle processing of different images or parts of an image simultaneously.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Ideal for CPU-bound Tasks:**\n",
        "\n",
        "- **CPU-bound tasks** are tasks that are constrained by the CPU’s processing power (e.g., large mathematical operations, video encoding, scientific simulations).\n",
        "- In such tasks, where the CPU is the bottleneck, multiprocessing allows multiple CPU cores to work on different parts of the task concurrently, leading to significant performance improvements.\n",
        "\n",
        "  **Example:** Processing large datasets or performing matrix operations in scientific computing or training machine learning models.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Memory Isolation:**\n",
        "\n",
        "- Each process created in multiprocessing has its own **separate memory space**, which provides memory isolation between processes. This means that if one process crashes or experiences memory corruption, it will not affect other processes.\n",
        "- This isolation is particularly useful for applications that require robust fault tolerance, where the failure of one component should not bring down the entire program.\n",
        "\n",
        "  **Example:** A web server can handle client requests in separate processes. If one process crashes, it doesn’t affect the other requests being handled by other processes.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Distributed Systems and Scalability:**\n",
        "\n",
        "- **Scalability:** Multiprocessing allows for **scaling** across multiple processors or even multiple machines in a distributed system. Processes can be distributed across multiple nodes, with each node handling its own subset of the task. This is especially useful for large-scale distributed applications.\n",
        "  \n",
        "  **Example:** Distributed computing frameworks like Apache Spark or Dask use multiprocessing concepts to distribute tasks over multiple nodes in a cluster.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Built-in Support in Python via the `multiprocessing` Module:**\n",
        "\n",
        "Python provides the `multiprocessing` module, which makes it easy to implement multiprocessing in programs without having to handle low-level process creation and management.\n",
        "\n",
        "#### Key features of the `multiprocessing` module:\n",
        "- **`Process`:** Allows creating new processes to run functions or tasks in parallel.\n",
        "- **`Pool`:** Manages a pool of worker processes and distributes tasks among them efficiently.\n",
        "- **`Queue`, `Pipe`:** Mechanisms for inter-process communication (IPC) to share data between processes.\n",
        "- **`Lock`, `Semaphore`:** Synchronization primitives to control access to shared resources between processes.\n",
        "\n",
        "---\n",
        "\n",
        "### **When is Multiprocessing Used?**\n",
        "\n",
        "#### **1. CPU-bound tasks that require a lot of computation:**\n",
        "- **Scientific computing and data analysis:** Large datasets or computationally intensive tasks like simulations, machine learning, or solving complex algorithms.\n",
        "  \n",
        "  **Example:** Training deep learning models, performing Monte Carlo simulations, or solving numerical equations.\n",
        "\n",
        "#### **2. Parallel execution of independent tasks:**\n",
        "- **Batch processing:** Multiprocessing is ideal when you need to process a large number of independent tasks in parallel, such as image processing, video rendering, or batch processing files.\n",
        "  \n",
        "  **Example:** A video editing software that processes different video frames in parallel across multiple processes.\n",
        "\n",
        "#### **3. Fault-tolerant and isolated environments:**\n",
        "- **Web servers:** Web servers can spawn separate processes for each client request to avoid crashing the entire server if a single process fails.\n",
        "  \n",
        "  **Example:** In a Flask or Django web server, multiprocessing can be used to handle multiple requests simultaneously in isolated environments.\n",
        "\n",
        "---\n",
        "\n",
        "### **Example of Multiprocessing in Python:**\n",
        "\n",
        "Here’s a simple example demonstrating the use of the `multiprocessing` module to perform CPU-bound tasks in parallel:\n",
        "\n",
        "```python\n",
        "import multiprocessing\n",
        "\n",
        "# Define a function to perform a CPU-bound task\n",
        "def square_number(n):\n",
        "    return n * n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "    # Create a pool of 4 worker processes\n",
        "    with multiprocessing.Pool(processes=4) as pool:\n",
        "        # Apply the square_number function to each number in the list\n",
        "        results = pool.map(square_number, numbers)\n",
        "\n",
        "    print(results)\n",
        "```\n",
        "\n",
        "#### **Explanation:**\n",
        "- A pool of 4 worker processes is created using `multiprocessing.Pool(processes=4)`.\n",
        "- The `pool.map()` function distributes the work (squaring the numbers) across the available processes.\n",
        "- Each worker process computes the square of a subset of the numbers, and the results are returned once all processes have finished.\n",
        "\n",
        "---\n",
        "\n",
        "### **Advantages of Multiprocessing:**\n",
        "\n",
        "1. **Bypasses the GIL**: Allows true parallelism for CPU-bound tasks, unlike multithreading, which is constrained by the GIL.\n",
        "2. **Efficient use of multiple CPU cores**: Multiprocessing fully utilizes multicore processors to perform CPU-intensive tasks faster.\n",
        "3. **Fault isolation**: Since each process has its own memory space, a failure in one process won’t affect others.\n",
        "4. **Scalability**: Can be scaled to run across multiple machines or processors in a distributed system.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion:**\n",
        "\n",
        "Multiprocessing is a powerful technique in Python for achieving true parallelism, particularly for CPU-bound tasks that require significant computation. By creating multiple processes, each with its own Python interpreter and memory space, multiprocessing bypasses the limitations of the GIL and efficiently utilizes multicore systems. It is commonly used in scientific computing, data processing, and other high-performance applications where CPU resources are the bottleneck."
      ],
      "metadata": {
        "id": "dmiO1bdW6v9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4."
      ],
      "metadata": {
        "id": "L79y1xJh7EDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4.Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
        "#thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
        "#threading.Lock.\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared list\n",
        "shared_list = []\n",
        "\n",
        "# Lock to prevent race conditions\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Function for adding numbers to the list\n",
        "def add_to_list():\n",
        "    for i in range(10):\n",
        "        time.sleep(1)  # Simulate some delay\n",
        "        with list_lock:  # Acquire the lock before modifying the list\n",
        "            shared_list.append(i)\n",
        "            print(f\"Added {i} to the list. List: {shared_list}\")\n",
        "\n",
        "# Function for removing numbers from the list\n",
        "def remove_from_list():\n",
        "    for i in range(10):\n",
        "        time.sleep(1.5)  # Simulate some delay\n",
        "        with list_lock:  # Acquire the lock before modifying the list\n",
        "            if shared_list:\n",
        "                removed = shared_list.pop(0)  # Remove the first element\n",
        "                print(f\"Removed {removed} from the list. List: {shared_list}\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove\")\n",
        "\n",
        "# Create two threads: one for adding and one for removing\n",
        "add_thread = threading.Thread(target=add_to_list)\n",
        "remove_thread = threading.Thread(target=remove_from_list)\n",
        "\n",
        "# Start the threads\n",
        "add_thread.start()\n",
        "remove_thread.start()\n",
        "\n",
        "# Wait for both threads to finish\n",
        "add_thread.join()\n",
        "remove_thread.join()\n",
        "\n",
        "print(\"Final list:\", shared_list)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AtGSjrKB7PJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5.Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
        "Ans.In Python, when using **threads** or **processes**, sharing data between them can lead to race conditions, data corruption, or inconsistencies if not handled properly. To safely share data between threads or processes, Python provides various synchronization primitives and tools. Here's a description of the key methods and tools available for safely sharing data between threads and processes:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Sharing Data Between Threads**\n",
        "\n",
        "Threads in Python share the same memory space, which allows them to access shared data. However, this can lead to race conditions if multiple threads try to modify the shared data simultaneously. To avoid this, Python provides the following tools for synchronization:\n",
        "\n",
        "#### **a. `threading.Lock`**\n",
        "- **Purpose:** A `Lock` is used to ensure that only one thread can access a shared resource at a time.\n",
        "- **How it works:** A thread must acquire the lock before modifying shared data, and release it after the operation is complete. If the lock is already acquired by another thread, the thread will wait until the lock becomes available.\n",
        "  \n",
        "  **Example:**\n",
        "  ```python\n",
        "  import threading\n",
        "\n",
        "  shared_data = 0\n",
        "  lock = threading.Lock()\n",
        "\n",
        "  def increment():\n",
        "      global shared_data\n",
        "      with lock:\n",
        "          shared_data += 1\n",
        "\n",
        "  ```\n",
        "\n",
        "#### **b. `threading.RLock` (Reentrant Lock)**\n",
        "- **Purpose:** An `RLock` (Reentrant Lock) is similar to a `Lock`, but allows a thread to acquire the lock multiple times without causing a deadlock.\n",
        "- **When to use:** Use `RLock` when a thread may need to lock the same resource multiple times (e.g., when one function that acquires a lock calls another function that also tries to acquire the lock).\n",
        "\n",
        "  **Example:**\n",
        "  ```python\n",
        "  rlock = threading.RLock()\n",
        "  ```\n",
        "\n",
        "#### **c. `threading.Semaphore`**\n",
        "- **Purpose:** A `Semaphore` is a synchronization primitive that allows a fixed number of threads to access a shared resource concurrently. It maintains a counter to limit the number of threads accessing the resource.\n",
        "- **How it works:** A thread can acquire the semaphore if the internal counter is greater than zero. The counter is decremented when a thread acquires the semaphore and incremented when the thread releases it.\n",
        "  \n",
        "  **Example:**\n",
        "  ```python\n",
        "  semaphore = threading.Semaphore(3)  # Only 3 threads can access the resource concurrently\n",
        "  ```\n",
        "\n",
        "#### **d. `threading.Event`**\n",
        "- **Purpose:** An `Event` is a simple synchronization mechanism that allows one thread to signal one or more threads that a particular event has occurred.\n",
        "- **How it works:** One thread can set the event (using `event.set()`), and other threads can wait for the event to be set (using `event.wait()`).\n",
        "\n",
        "  **Example:**\n",
        "  ```python\n",
        "  event = threading.Event()\n",
        "\n",
        "  def wait_for_event():\n",
        "      event.wait()\n",
        "      print(\"Event occurred!\")\n",
        "  ```\n",
        "\n",
        "#### **e. `threading.Condition`**\n",
        "- **Purpose:** A `Condition` is used to wait for a certain condition to be met before allowing a thread to proceed. It combines a lock with a signaling mechanism (like an event).\n",
        "- **How it works:** A thread can acquire the condition, then call `wait()` to release the lock and wait until another thread calls `notify()` or `notify_all()` to signal that the condition is met.\n",
        "\n",
        "  **Example:**\n",
        "  ```python\n",
        "  condition = threading.Condition()\n",
        "\n",
        "  def producer():\n",
        "      with condition:\n",
        "          # Produce data\n",
        "          condition.notify()  # Signal the consumer\n",
        "\n",
        "  def consumer():\n",
        "      with condition:\n",
        "          condition.wait()  # Wait for the signal\n",
        "  ```\n",
        "\n",
        "#### **f. Thread-safe Data Structures (`queue.Queue`)**\n",
        "- **Purpose:** The `queue.Queue` class is a thread-safe FIFO queue. It can be used to safely share data between threads without worrying about locks.\n",
        "- **How it works:** The `Queue` internally handles the locking mechanisms to ensure that only one thread accesses the data at a time.\n",
        "  \n",
        "  **Example:**\n",
        "  ```python\n",
        "  import queue\n",
        "\n",
        "  q = queue.Queue()\n",
        "\n",
        "  def producer():\n",
        "      for i in range(5):\n",
        "          q.put(i)  # Safely add items to the queue\n",
        "\n",
        "  def consumer():\n",
        "      while not q.empty():\n",
        "          item = q.get()  # Safely get items from the queue\n",
        "          print(f\"Consumed {item}\")\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Sharing Data Between Processes**\n",
        "\n",
        "Processes in Python do not share memory space by default, so sharing data between them is more complex than with threads. However, Python’s `multiprocessing` module provides various tools to safely share data between processes:\n",
        "\n",
        "#### **a. `multiprocessing.Queue`**\n",
        "- **Purpose:** A `multiprocessing.Queue` is a FIFO queue that allows safe communication between processes. It is designed for sharing data between processes and is fully synchronized.\n",
        "- **How it works:** Processes can put data into the queue, and other processes can retrieve it. Internally, the queue uses locks and semaphores to ensure safe access.\n",
        "  \n",
        "  **Example:**\n",
        "  ```python\n",
        "  from multiprocessing import Process, Queue\n",
        "\n",
        "  def producer(q):\n",
        "      for i in range(5):\n",
        "          q.put(i)\n",
        "\n",
        "  def consumer(q):\n",
        "      while not q.empty():\n",
        "          item = q.get()\n",
        "          print(f\"Consumed {item}\")\n",
        "\n",
        "  q = Queue()\n",
        "  p1 = Process(target=producer, args=(q,))\n",
        "  p2 = Process(target=consumer, args=(q,))\n",
        "\n",
        "  p1.start()\n",
        "  p2.start()\n",
        "  p1.join()\n",
        "  p2.join()\n",
        "  ```\n",
        "\n",
        "#### **b. `multiprocessing.Pipe`**\n",
        "- **Purpose:** A `Pipe` provides a two-way communication channel between two processes. Data can be sent from one process to another through the pipe.\n",
        "- **How it works:** Two ends of the pipe are created, and each process can use one end of the pipe to send or receive data.\n",
        "  \n",
        "  **Example:**\n",
        "  ```python\n",
        "  from multiprocessing import Process, Pipe\n",
        "\n",
        "  def producer(pipe):\n",
        "      pipe.send(\"Hello from producer\")\n",
        "\n",
        "  def consumer(pipe):\n",
        "      print(pipe.recv())\n",
        "\n",
        "  parent_conn, child_conn = Pipe()\n",
        "  p1 = Process(target=producer, args=(child_conn,))\n",
        "  p2 = Process(target=consumer, args=(parent_conn,))\n",
        "\n",
        "  p1.start()\n",
        "  p2.start()\n",
        "  p1.join()\n",
        "  p2.join()\n",
        "  ```\n",
        "\n",
        "#### **c. `multiprocessing.Manager`**\n",
        "- **Purpose:** A `Manager` provides a way to share objects (such as lists, dictionaries, etc.) between processes. It creates shared objects that can be modified by multiple processes concurrently.\n",
        "- **How it works:** The `Manager` creates proxies for shared objects (like lists, dictionaries) that can be accessed and modified by different processes.\n",
        "  \n",
        "  **Example:**\n",
        "  ```python\n",
        "  from multiprocessing import Manager, Process\n",
        "\n",
        "  def modify_list(shared_list):\n",
        "      shared_list.append(\"New item\")\n",
        "\n",
        "  if __name__ == \"__main__\":\n",
        "      manager = Manager()\n",
        "      shared_list = manager.list()\n",
        "\n",
        "      p1 = Process(target=modify_list, args=(shared_list,))\n",
        "      p1.start()\n",
        "      p1.join()\n",
        "\n",
        "      print(shared_list)\n",
        "  ```\n",
        "\n",
        "#### **d. `multiprocessing.Value` and `Array`**\n",
        "- **Purpose:** `Value` and `Array` allow you to share simple data types (like integers or arrays) between processes. These objects are stored in shared memory and can be accessed by multiple processes.\n",
        "- **How it works:** `Value` creates a shared object that can be used to store a single value, while `Array` allows sharing an array of values.\n",
        "  \n",
        "  **Example:**\n",
        "  ```python\n",
        "  from multiprocessing import Process, Value\n",
        "\n",
        "  def increment(val):\n",
        "      with val.get_lock():  # Ensure safe access\n",
        "          val.value += 1\n",
        "\n",
        "  shared_value = Value('i', 0)  # 'i' means an integer\n",
        "  p1 = Process(target=increment, args=(shared_value,))\n",
        "  p2 = Process(target=increment, args=(shared_value,))\n",
        "\n",
        "  p1.start()\n",
        "  p2.start()\n",
        "  p1.join()\n",
        "  p2.join()\n",
        "\n",
        "  print(shared_value.value)\n",
        "  ```\n",
        "\n",
        "#### **e. `multiprocessing.Lock` and `Semaphore`**\n",
        "- **Purpose:** Similar to threading, you can use `Lock` or `Semaphore` to synchronize access to shared resources between processes.\n",
        "- **How it works:** A `Lock` ensures that only one process can access a resource at a time, while a `Semaphore` allows a limited number of processes to access the resource concurrently.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "In Python, safely sharing data between threads or processes requires synchronization mechanisms to avoid race conditions and ensure data consistency. For **threads**, tools like `Lock`, `RLock`, `Semaphore`, and thread-safe data structures like `queue.Queue` are commonly used. For **processes**, Python provides tools like `multiprocessing.Queue`, `Pipe`, `Manager`, `Value`, and `Array`, which allow for safe and efficient communication between processes."
      ],
      "metadata": {
        "id": "qGa35ag47cZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
        "Ans.Handling exceptions in concurrent programs is crucial for ensuring the **correctness, stability, and robustness** of applications. In concurrent programs—whether using **threads** or **processes**—exceptions can lead to resource leaks, race conditions, inconsistent state, deadlocks, and application crashes. Proper exception handling allows for better debugging, resource management, and recovery from unexpected errors, preventing the entire program from failing due to an error in one concurrent task.\n",
        "\n",
        "Here’s why handling exceptions in concurrent programs is important, along with techniques available in Python for managing them.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why Exception Handling is Crucial in Concurrent Programs**\n",
        "\n",
        "1. **Resource Management:**\n",
        "   - Threads and processes often share or access critical resources (like files, network connections, or shared data structures). If an exception occurs in one thread or process without proper handling, these resources may not be released properly, leading to **resource leaks** (e.g., file handles not being closed or locks not being released).\n",
        "   - This can degrade performance, eventually causing the program to run out of resources, such as memory or file descriptors.\n",
        "\n",
        "2. **Preventing Data Corruption:**\n",
        "   - In concurrent programs, multiple threads or processes may access shared resources. If an exception occurs during a critical operation (such as modifying shared data), it can leave the program in an inconsistent or corrupted state. Without exception handling, this corrupted state could propagate to other parts of the program.\n",
        "   - This is especially important in **multithreading**, where data corruption can occur due to race conditions if one thread is interrupted by an exception.\n",
        "\n",
        "3. **Ensuring Robustness and Stability:**\n",
        "   - Uncaught exceptions in threads or processes may cause them to silently terminate, leaving other parts of the program in an inconsistent state. Proper exception handling ensures that errors are logged or handled gracefully, allowing the application to recover or retry the failed operation.\n",
        "   - It prevents the entire program from crashing due to unhandled exceptions in one part of the concurrent system.\n",
        "\n",
        "4. **Debugging and Monitoring:**\n",
        "   - If exceptions are not handled correctly in concurrent programs, they may be swallowed or go unnoticed, making it difficult to diagnose the root cause of an issue. Proper handling ensures that the exceptions are **logged, raised, or communicated** back to the main thread, aiding debugging and monitoring.\n",
        "\n",
        "---\n",
        "\n",
        "### **Techniques for Handling Exceptions in Concurrent Python Programs**\n",
        "\n",
        "Python provides various techniques for handling exceptions in **multithreading** and **multiprocessing** programs:\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Handling Exceptions in Threads**\n",
        "\n",
        "When using **threads**, it’s important to note that if an exception occurs in a thread, it **does not automatically propagate** back to the main thread. This makes it necessary to catch exceptions within the thread itself and handle or report them appropriately.\n",
        "\n",
        "##### **a. Using `try-except` Blocks Inside Threads**\n",
        "The simplest way to handle exceptions in threads is to use `try-except` blocks within the thread’s target function. This allows you to catch and handle any errors that occur during the thread’s execution.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "import threading\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        # Simulating a task that raises an exception\n",
        "        raise ValueError(\"Something went wrong in the thread!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred in thread: {e}\")\n",
        "\n",
        "# Create and start the thread\n",
        "t = threading.Thread(target=worker)\n",
        "t.start()\n",
        "t.join()\n",
        "```\n",
        "\n",
        "In this example, the exception is caught within the thread and logged, allowing the program to continue running even if the thread encounters an error.\n",
        "\n",
        "##### **b. Returning Exceptions to the Main Thread**\n",
        "To propagate exceptions back to the main thread (for logging or further handling), you can store the exception in a shared data structure (e.g., a list or `queue.Queue`), and check for exceptions in the main thread after the thread has finished executing.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "import threading\n",
        "import queue\n",
        "\n",
        "exception_queue = queue.Queue()\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        raise ValueError(\"Error in worker thread\")\n",
        "    except Exception as e:\n",
        "        exception_queue.put(e)\n",
        "\n",
        "# Create and start the thread\n",
        "t = threading.Thread(target=worker)\n",
        "t.start()\n",
        "t.join()\n",
        "\n",
        "# Check for exceptions after the thread completes\n",
        "if not exception_queue.empty():\n",
        "    exception = exception_queue.get()\n",
        "    print(f\"Exception in thread: {exception}\")\n",
        "```\n",
        "\n",
        "This technique allows the main thread to be notified of exceptions raised in worker threads and handle them accordingly.\n",
        "\n",
        "##### **c. Using Custom Thread Classes to Catch Exceptions**\n",
        "Another way to handle exceptions is by subclassing `threading.Thread` and adding exception handling in the custom thread class. This allows for more advanced handling (e.g., retrying failed operations).\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "import threading\n",
        "\n",
        "class MyThread(threading.Thread):\n",
        "    def run(self):\n",
        "        try:\n",
        "            raise ValueError(\"Error in custom thread\")\n",
        "        except Exception as e:\n",
        "            print(f\"Exception caught in custom thread: {e}\")\n",
        "\n",
        "# Start the custom thread\n",
        "t = MyThread()\n",
        "t.start()\n",
        "t.join()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Handling Exceptions in Processes**\n",
        "\n",
        "In **multiprocessing**, exceptions raised in a child process do not automatically propagate to the parent process. Python’s `multiprocessing` module provides several ways to handle exceptions in processes.\n",
        "\n",
        "##### **a. Using `try-except` Blocks Inside Processes**\n",
        "Just like in threading, you can use `try-except` blocks within the target function of a process to catch and handle exceptions.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "from multiprocessing import Process\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        raise ValueError(\"Something went wrong in the process!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred in process: {e}\")\n",
        "\n",
        "p = Process(target=worker)\n",
        "p.start()\n",
        "p.join()\n",
        "```\n",
        "\n",
        "##### **b. Using `multiprocessing.Pool` and Handling Exceptions in Worker Processes**\n",
        "When using `multiprocessing.Pool`, exceptions raised in worker processes can be captured and propagated back to the main process via the `apply_async()` method or by checking the `get()` method of the pool result.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def worker(x):\n",
        "    if x == 5:\n",
        "        raise ValueError(\"Invalid value!\")\n",
        "    return x * 2\n",
        "\n",
        "def handle_error(e):\n",
        "    print(f\"Error in pool worker: {e}\")\n",
        "\n",
        "pool = Pool(4)\n",
        "\n",
        "# Using apply_async to handle exceptions\n",
        "results = [pool.apply_async(worker, args=(i,), error_callback=handle_error) for i in range(10)]\n",
        "\n",
        "# Wait for results\n",
        "for result in results:\n",
        "    try:\n",
        "        print(result.get())  # This will raise if the worker function failed\n",
        "    except Exception as e:\n",
        "        print(f\"Exception caught in main process: {e}\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "```\n",
        "\n",
        "In this example, the `error_callback` parameter in `apply_async()` is used to catch exceptions raised in the worker processes and handle them in the main process.\n",
        "\n",
        "##### **c. Using `multiprocessing.Queue` or `Pipe` to Return Exceptions**\n",
        "Similar to threads, you can use a `multiprocessing.Queue` or `Pipe` to pass exceptions from worker processes back to the parent process.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def worker(q):\n",
        "    try:\n",
        "        raise ValueError(\"Error in worker process\")\n",
        "    except Exception as e:\n",
        "        q.put(e)\n",
        "\n",
        "q = Queue()\n",
        "p = Process(target=worker, args=(q,))\n",
        "p.start()\n",
        "p.join()\n",
        "\n",
        "# Check for exceptions\n",
        "if not q.empty():\n",
        "    exception = q.get()\n",
        "    print(f\"Exception in process: {exception}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Best Practices for Exception Handling in Concurrent Programs**\n",
        "\n",
        "1. **Use Try-Except Blocks in Target Functions:**\n",
        "   - Always wrap the main logic of threads and processes in a `try-except` block to catch and handle exceptions directly in the worker functions.\n",
        "\n",
        "2. **Report Exceptions Back to the Main Thread/Process:**\n",
        "   - Use shared data structures (`queue.Queue`, `multiprocessing.Queue`, etc.) to report exceptions from worker threads or processes back to the main thread or parent process for logging and handling.\n",
        "\n",
        "3. **Ensure Cleanup in Case of Exceptions:**\n",
        "   - Use `finally` blocks or context managers to ensure that resources (e.g., file handles, database connections, locks) are properly released, even if an exception occurs.\n",
        "\n",
        "4. **Consider Retrying or Graceful Shutdown:**\n",
        "   - If a critical task fails, you might want to implement a retry mechanism or handle errors gracefully, allowing the system to recover or shut down safely without causing further issues.\n",
        "\n",
        "5. **Log Exceptions:**\n",
        "   - Always log exceptions with detailed information, including the type of error and a stack trace, to facilitate debugging and ensure that any issues can be traced back later.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "Handling exceptions in concurrent programs is essential for preventing resource leaks, data corruption, and application crashes. In Python, `try-except` blocks, thread-safe queues, and custom thread or process classes allow for proper handling and reporting of exceptions in both **multithreading** and **multiprocessing** contexts. Techniques like using shared queues to communicate exceptions back to the main thread/process ensure that the program remains robust and failures are properly addressed."
      ],
      "metadata": {
        "id": "3fWqTaxh74qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "Ans.Here’s a Python program that uses `concurrent.futures.ThreadPoolExecutor` to calculate the factorial of numbers from 1 to 10 concurrently:\n",
        "\n",
        "```python\n",
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial\n",
        "def factorial(n):\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main function to use ThreadPoolExecutor\n",
        "def main():\n",
        "    numbers = list(range(1, 11))  # Numbers from 1 to 10\n",
        "\n",
        "    # Create a thread pool\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Submit tasks to the thread pool and get results\n",
        "        results = list(executor.map(factorial, numbers))\n",
        "\n",
        "    # Print results\n",
        "    for num, result in zip(numbers, results):\n",
        "        print(f\"Factorial of {num} is {result}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "1. **Function `factorial`:**\n",
        "   - This function takes a number `n` and returns its factorial using `math.factorial(n)`. It also prints a message indicating which number's factorial is being calculated.\n",
        "\n",
        "2. **ThreadPoolExecutor:**\n",
        "   - In the `main()` function, we use a `ThreadPoolExecutor` to manage a pool of threads. The `map` method allows us to apply the `factorial` function concurrently to each number in the `numbers` list.\n",
        "   - `map(factorial, numbers)` schedules the tasks and returns an iterator that provides the results once available. In this case, the results are stored in the `results` list.\n",
        "\n",
        "3. **Printing Results:**\n",
        "   - After all threads have finished their computations, we print the calculated factorials for numbers 1 to 10.\n",
        "\n",
        "### Sample Output:\n",
        "\n",
        "```\n",
        "Calculating factorial of 1\n",
        "Calculating factorial of 2\n",
        "Calculating factorial of 3\n",
        "Calculating factorial of 4\n",
        "Calculating factorial of 5\n",
        "Calculating factorial of 6\n",
        "Calculating factorial of 7\n",
        "Calculating factorial of 8\n",
        "Calculating factorial of 9\n",
        "Calculating factorial of 10\n",
        "Factorial of 1 is 1\n",
        "Factorial of 2 is 2\n",
        "Factorial of 3 is 6\n",
        "Factorial of 4 is 24\n",
        "Factorial of 5 is 120\n",
        "Factorial of 6 is 720\n",
        "Factorial of 7 is 5040\n",
        "Factorial of 8 is 40320\n",
        "Factorial of 9 is 362880\n",
        "Factorial of 10 is 3628800\n",
        "```\n",
        "\n",
        "This program demonstrates how to manage concurrent tasks efficiently using the `ThreadPoolExecutor` to compute the factorials concurrently."
      ],
      "metadata": {
        "id": "rXSA4qnc8RDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8.Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 inparallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).\n",
        "Ans.Here's a Python program that uses `multiprocessing.Pool` to compute the square of numbers from 1 to 10 in parallel. The program will measure the time taken for computations using different pool sizes (2, 4, and 8 processes).\n",
        "\n",
        "```python\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Main function to compute squares with a pool of processes\n",
        "def compute_squares(pool_size):\n",
        "    numbers = list(range(1, 11))  # Numbers from 1 to 10\n",
        "    with multiprocessing.Pool(processes=pool_size) as pool:\n",
        "        results = pool.map(square, numbers)\n",
        "    return results\n",
        "\n",
        "# Function to measure time taken for computations\n",
        "def measure_time(pool_size):\n",
        "    start_time = time.time()\n",
        "    results = compute_squares(pool_size)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    return results, elapsed_time\n",
        "\n",
        "# Main entry point\n",
        "if __name__ == \"__main__\":\n",
        "    pool_sizes = [2, 4, 8]  # Different pool sizes\n",
        "\n",
        "    for size in pool_sizes:\n",
        "        results, elapsed_time = measure_time(size)\n",
        "        print(f\"Results with pool size {size}: {results}\")\n",
        "        print(f\"Time taken: {elapsed_time:.4f} seconds\\n\")\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "1. **Function `square`:** This function takes a number `n` and returns its square.\n",
        "\n",
        "2. **Function `compute_squares`:**\n",
        "   - This function takes the pool size as an argument and uses a `multiprocessing.Pool` to create a pool of worker processes.\n",
        "   - It then uses the `map` method to apply the `square` function to the list of numbers from 1 to 10.\n",
        "\n",
        "3. **Function `measure_time`:**\n",
        "   - This function measures the time taken to compute the squares by calling `compute_squares` and returns the results along with the elapsed time.\n",
        "\n",
        "4. **Main Execution:**\n",
        "   - In the `if __name__ == \"__main__\"` block, the program iterates over the specified pool sizes (2, 4, and 8) and calls `measure_time` for each size. It prints the results and the time taken for each pool size.\n",
        "\n",
        "### Running the Program:\n",
        "When you run the program, it will compute the squares of numbers from 1 to 10 using different pool sizes and display the results along with the time taken for each computation.\n",
        "\n",
        "### Sample Output:\n",
        "```\n",
        "Results with pool size 2: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
        "Time taken: 0.0024 seconds\n",
        "\n",
        "Results with pool size 4: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
        "Time taken: 0.0018 seconds\n",
        "\n",
        "Results with pool size 8: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
        "Time taken: 0.0015 seconds\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "L-6PhCU28ix5"
      }
    }
  ]
}